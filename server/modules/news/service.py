# server/services/news_service.py
from typing import Iterable, Optional, List, Tuple
from datetime import datetime
from fastapi import Request
import re
# Whitelist cÃ¡c cá»™t cho phÃ©p SELECT & SORT
ALLOWED_FIELDS = {
    "id", "title", "url", "description", "published_time", "section", "thumbnail", "view_count"
}
ALLOWED_SORT = {"published_time", "title", "section", "id", "view_count"}

def _normalize_fields(fields: Optional[Iterable[str]]) -> List[str]:
    """
    Giá»¯ láº¡i nhá»¯ng cá»™t há»£p lá»‡ theo whitelist; náº¿u rá»—ng â†’ tráº£ bá»™ máº·c Ä‘á»‹nh.
    """
    if not fields:
        return ["id", "title", "url", "description", "published_time", "section", "thumbnail", "view_count"]
    out: List[str] = []
    for f in fields:
        if not f:
            continue
        fx = f.strip()
        if fx in ALLOWED_FIELDS:
            out.append(fx)
    return out or ["id"]

def _normalize_sort(order_by: Optional[str], order_dir: Optional[str]) -> Tuple[str, str]:
    col = order_by if order_by in ALLOWED_SORT else "published_time"
    dir_ = (order_dir or "DESC").upper()
    if dir_ not in ("ASC", "DESC"):
        dir_ = "DESC"
    return col, dir_

def normalize_section(section: str) -> str:
    if not section:
        return ""
    s = section.strip().lower()
    s = s.replace("&", "and")
    s = s.replace("-", " ")           # âœ… thÃªm bÆ°á»›c nÃ y
    s = re.sub(r"[,]", " ", s)       # thay dáº¥u pháº©y báº±ng khoáº£ng tráº¯ng
    s = re.sub(r"\s+", " ", s)       # xÃ³a khoáº£ng tráº¯ng thá»«a
    s = s.replace("/", " / ")         # thÃªm khoáº£ng tráº¯ng quanh /
    s = re.sub(r"\s+/+\s+", " / ", s)  # Ä‘áº£m báº£o chá»‰ 1 khoáº£ng tráº¯ng xung quanh /
    return s.strip()

async def list_news(
    request: Request,
    fields: Optional[Iterable[str]] = None,
    sections: Optional[List[str]] = None,   # Ä‘Ã£ normalize á»Ÿ router
    date_from: Optional[datetime] = None,
    date_to: Optional[datetime] = None,
    q: Optional[str] = None,
    limit: int = 20,
    offset: int = 0,
    order_by: Optional[str] = "published_time",
    order_dir: Optional[str] = "DESC",
):
    # Chuáº©n hoÃ¡ tá»‘i thiá»ƒu
    q = (q or "").strip() or None
    order_dir = (order_dir or "DESC").upper()

    pool = request.app.state.pool

    # 1) SELECT
    select_cols = _normalize_fields(fields)
    select_sql = ", ".join(select_cols)

    # 2) WHERE + params
    where_parts: List[str] = []
    params: List[object] = []

    if sections:
        normalized_sections = [normalize_section(s) for s in sections if s]
        # print(">>> Original sections:", sections)
        # print(">>> Normalized sections:", normalized_sections)

        # Chá»‰ dÃ¹ng section Ä‘áº§u tiÃªn (hoáº·c báº¡n cÃ³ thá»ƒ loop tá»«ng section náº¿u cáº§n)
        sec = normalized_sections[0]
        params.append(sec)

        where_parts.append(f"""
            regexp_replace(
                lower(replace(section, '&', 'and')),
                '[^a-z0-9/]', '', 'g'
            ) ILIKE '%' || regexp_replace(
                lower(replace(${len(params)}, '&', 'and')),
                '[^a-z0-9/]', '', 'g'
            ) || '%'
        """)

    if date_from:
        params.append(date_from)
        where_parts.append(f"published_time >= ${len(params)}")

    if date_to:
        params.append(date_to)
        where_parts.append(f"published_time <= ${len(params)}")

    if q:
        # ğŸ§¹ Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, chá»‰ giá»¯ láº¡i chá»¯, sá»‘ vÃ  khoáº£ng tráº¯ng
        cleaned_q = re.sub(r"[^a-zA-Z0-9\s]", " ", q)
        keywords = cleaned_q.split()
        where_like_parts = []

        for word in keywords:
            like = f"%{word}%"
            params.append(like); t_idx = len(params)
            params.append(like); d_idx = len(params)
            params.append(like); id_idx = len(params)
            print(f"LIKE conditions: title={like}, description={like}, id={like}")
            where_like_parts.append(
                f"(title ILIKE ${t_idx} OR description ILIKE ${d_idx} OR CAST(id AS TEXT) ILIKE ${id_idx})"
            )

        # ğŸ”„ Chuyá»ƒn sang tÃ¬m kiáº¿m rá»™ng (chá»‰ cáº§n khá»›p 1 tá»« khÃ³a)
        where_parts.append("(" + " OR ".join(where_like_parts) + ")")

    # âœ… GhÃ©p WHERE SQL cuá»‘i cÃ¹ng (ngoÃ i if)
    where_sql = f"WHERE {' AND '.join(where_parts)}" if where_parts else ""

    # 3) SORT + PAGINATION
    sort_col, sort_dir = _normalize_sort(order_by, order_dir)
    if limit <= 0 or limit > 1000:
        limit = 20
    if offset < 0:
        offset = 0

    # 4) Query
    sql = f"""
        SELECT {select_sql}
        FROM news
        {where_sql}
        ORDER BY {sort_col} {sort_dir} NULLS LAST
        LIMIT {limit} OFFSET {offset}
    """
    count_sql = f"SELECT COUNT(*) FROM news {where_sql}"

    async with pool.acquire() as conn:
        rows = await conn.fetch(sql, *params)
        items = [dict(r) for r in rows]
        total = await conn.fetchval(count_sql, *params)

    return {
        "items": items,
        "page": {"limit": limit, "offset": offset, "total": total},
        "meta": {"fields": select_cols, "order_by": sort_col, "order_dir": sort_dir},
    }

async def get_news_by_id(request: Request, news_id: str):
    pool = request.app.state.pool
    sql = """
        SELECT 
            id,
            title,
            url,
            description,
            article,
            section,
            published_time,
            view_count
        FROM news
        WHERE id = $1
        LIMIT 1;
    """
    async with pool.acquire() as conn:
        row = await conn.fetchrow(sql, news_id)

    return dict(row) if row else None
